{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\")\n",
    "from transformers import AutoModel, BertTokenizerFast,RobertaTokenizer, RobertaModel,DistilBertTokenizer, DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "# Import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Roberta tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "# Import Roberta pretrained model\n",
    "bert = RobertaModel.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DistilBert tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "# Import the DistilBert pretrained model\n",
    "bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2023,  2003,  1037,  4487, 16643,  2140, 14324,  2944,  1012,\n",
      "           102],\n",
      "        [  101,  2951,  2003,  3514,   102,     0,     0,     0,     0,     0,\n",
      "             0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "text = [\"this is a distil bert model.\",\"data is oil\"]\n",
    "# Encode the text\n",
    "encoded_input = tokenizer(text, padding=True,truncation=True, return_tensors='pt')\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.333333\n",
       "4    0.277778\n",
       "3    0.166667\n",
       "1    0.166667\n",
       "0    0.055556\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have prepared a chitchat dataset with 5 labels\n",
    "df = pd.read_csv(\"C:/Users/sohay/OneDrive/Desktop/BERT/chitchat - Sheet1.csv\")\n",
    "df.head()\n",
    "df[\"label\"].value_counts()\n",
    "# Converting the labels into encodings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'])\n",
    "# check class distribution\n",
    "df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example we have used all the utterances for training purpose\n",
    "train_text, train_labels = df[\"Text\"], df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "pd.Series(seq_len).hist(bins = 10)\n",
    "# Based on the histogram we are selecting the max len as 8\n",
    "max_seq_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer(\n",
    "    train_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "#define a batch size\n",
    "batch_size = 16\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "# DataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "   def __init__(self, bert):      \n",
    "       super(BERT_Arch, self).__init__()\n",
    "       self.bert = bert \n",
    "      \n",
    "       # dropout layer\n",
    "       self.dropout = nn.Dropout(0.2)\n",
    "      \n",
    "       # relu activation function\n",
    "       self.relu =  nn.ReLU()\n",
    "       # dense layer\n",
    "       self.fc1 = nn.Linear(768,512)\n",
    "       self.fc2 = nn.Linear(512,256)\n",
    "       self.fc3 = nn.Linear(256,5)\n",
    "       #softmax activation function\n",
    "       self.softmax = nn.LogSoftmax(dim=1)\n",
    "       #define the forward pass\n",
    "   def forward(self, sent_id, mask):\n",
    "      #pass the inputs to the model  \n",
    "      cls_hs = self.bert(sent_id, attention_mask=mask)[0][:,0]\n",
    "      \n",
    "      x = self.fc1(cls_hs)\n",
    "      x = self.relu(x)\n",
    "      x = self.dropout(x)\n",
    "      \n",
    "      x = self.fc2(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.dropout(x)\n",
    "      # output layer\n",
    "      x = self.fc3(x)\n",
    "   \n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "BERT_Arch                                               --\n",
       "├─DistilBertModel: 1-1                                  --\n",
       "│    └─Embeddings: 2-1                                  --\n",
       "│    │    └─Embedding: 3-1                              (23,440,896)\n",
       "│    │    └─Embedding: 3-2                              (393,216)\n",
       "│    │    └─LayerNorm: 3-3                              (1,536)\n",
       "│    │    └─Dropout: 3-4                                --\n",
       "│    └─Transformer: 2-2                                 --\n",
       "│    │    └─ModuleList: 3-5                             (42,527,232)\n",
       "├─Dropout: 1-2                                          --\n",
       "├─ReLU: 1-3                                             --\n",
       "├─Linear: 1-4                                           393,728\n",
       "├─Linear: 1-5                                           131,328\n",
       "├─Linear: 1-6                                           1,285\n",
       "├─LogSoftmax: 1-7                                       --\n",
       "================================================================================\n",
       "Total params: 66,889,221\n",
       "Trainable params: 526,341\n",
       "Non-trainable params: 66,362,880\n",
       "================================================================================"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freeze all the parameters. This will prevent updating of model weights during fine-tuning.\n",
    "for param in bert.parameters():\n",
    "      param.requires_grad = False\n",
    "model = BERT_Arch(bert)\n",
    "# push the model to GPU\n",
    "model = model.to(device)\n",
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.6  1.2  0.6  1.2  0.72]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "#compute the class weights\n",
    "class_wts = compute_class_weight(class_weight = \"balanced\",\n",
    "                                        classes = np.unique(train_labels),\n",
    "                                        y = train_labels)\n",
    "print(class_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "# loss function\n",
    "cross_entropy = nn.NLLLoss(weight=weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists to store training and validation loss of each epoch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "train_losses=[]\n",
    "# number of training epochs\n",
    "epochs = 200\n",
    "# We can also use learning rate scheduler to achieve better results\n",
    "lr_sch = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "  model.train()\n",
    "  total_loss = 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step,len(train_dataloader)))\n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch] \n",
    "    sent_id, mask, labels = batch\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "    # clip the the gradients to 1.0. It helps in preventing the    exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    # clear calculated gradients\n",
    "    optimizer.zero_grad()\n",
    "  \n",
    "    # We are not using learning rate scheduler as of now\n",
    "    # lr_sch.step()\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "    \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 200\n",
      "\n",
      " Epoch 2 / 200\n",
      "\n",
      " Epoch 3 / 200\n",
      "\n",
      " Epoch 4 / 200\n",
      "\n",
      " Epoch 5 / 200\n",
      "\n",
      " Epoch 6 / 200\n",
      "\n",
      " Epoch 7 / 200\n",
      "\n",
      " Epoch 8 / 200\n",
      "\n",
      " Epoch 9 / 200\n",
      "\n",
      " Epoch 10 / 200\n",
      "\n",
      " Epoch 11 / 200\n",
      "\n",
      " Epoch 12 / 200\n",
      "\n",
      " Epoch 13 / 200\n",
      "\n",
      " Epoch 14 / 200\n",
      "\n",
      " Epoch 15 / 200\n",
      "\n",
      " Epoch 16 / 200\n",
      "\n",
      " Epoch 17 / 200\n",
      "\n",
      " Epoch 18 / 200\n",
      "\n",
      " Epoch 19 / 200\n",
      "\n",
      " Epoch 20 / 200\n",
      "\n",
      " Epoch 21 / 200\n",
      "\n",
      " Epoch 22 / 200\n",
      "\n",
      " Epoch 23 / 200\n",
      "\n",
      " Epoch 24 / 200\n",
      "\n",
      " Epoch 25 / 200\n",
      "\n",
      " Epoch 26 / 200\n",
      "\n",
      " Epoch 27 / 200\n",
      "\n",
      " Epoch 28 / 200\n",
      "\n",
      " Epoch 29 / 200\n",
      "\n",
      " Epoch 30 / 200\n",
      "\n",
      " Epoch 31 / 200\n",
      "\n",
      " Epoch 32 / 200\n",
      "\n",
      " Epoch 33 / 200\n",
      "\n",
      " Epoch 34 / 200\n",
      "\n",
      " Epoch 35 / 200\n",
      "\n",
      " Epoch 36 / 200\n",
      "\n",
      " Epoch 37 / 200\n",
      "\n",
      " Epoch 38 / 200\n",
      "\n",
      " Epoch 39 / 200\n",
      "\n",
      " Epoch 40 / 200\n",
      "\n",
      " Epoch 41 / 200\n",
      "\n",
      " Epoch 42 / 200\n",
      "\n",
      " Epoch 43 / 200\n",
      "\n",
      " Epoch 44 / 200\n",
      "\n",
      " Epoch 45 / 200\n",
      "\n",
      " Epoch 46 / 200\n",
      "\n",
      " Epoch 47 / 200\n",
      "\n",
      " Epoch 48 / 200\n",
      "\n",
      " Epoch 49 / 200\n",
      "\n",
      " Epoch 50 / 200\n",
      "\n",
      " Epoch 51 / 200\n",
      "\n",
      " Epoch 52 / 200\n",
      "\n",
      " Epoch 53 / 200\n",
      "\n",
      " Epoch 54 / 200\n",
      "\n",
      " Epoch 55 / 200\n",
      "\n",
      " Epoch 56 / 200\n",
      "\n",
      " Epoch 57 / 200\n",
      "\n",
      " Epoch 58 / 200\n",
      "\n",
      " Epoch 59 / 200\n",
      "\n",
      " Epoch 60 / 200\n",
      "\n",
      " Epoch 61 / 200\n",
      "\n",
      " Epoch 62 / 200\n",
      "\n",
      " Epoch 63 / 200\n",
      "\n",
      " Epoch 64 / 200\n",
      "\n",
      " Epoch 65 / 200\n",
      "\n",
      " Epoch 66 / 200\n",
      "\n",
      " Epoch 67 / 200\n",
      "\n",
      " Epoch 68 / 200\n",
      "\n",
      " Epoch 69 / 200\n",
      "\n",
      " Epoch 70 / 200\n",
      "\n",
      " Epoch 71 / 200\n",
      "\n",
      " Epoch 72 / 200\n",
      "\n",
      " Epoch 73 / 200\n",
      "\n",
      " Epoch 74 / 200\n",
      "\n",
      " Epoch 75 / 200\n",
      "\n",
      " Epoch 76 / 200\n",
      "\n",
      " Epoch 77 / 200\n",
      "\n",
      " Epoch 78 / 200\n",
      "\n",
      " Epoch 79 / 200\n",
      "\n",
      " Epoch 80 / 200\n",
      "\n",
      " Epoch 81 / 200\n",
      "\n",
      " Epoch 82 / 200\n",
      "\n",
      " Epoch 83 / 200\n",
      "\n",
      " Epoch 84 / 200\n",
      "\n",
      " Epoch 85 / 200\n",
      "\n",
      " Epoch 86 / 200\n",
      "\n",
      " Epoch 87 / 200\n",
      "\n",
      " Epoch 88 / 200\n",
      "\n",
      " Epoch 89 / 200\n",
      "\n",
      " Epoch 90 / 200\n",
      "\n",
      " Epoch 91 / 200\n",
      "\n",
      " Epoch 92 / 200\n",
      "\n",
      " Epoch 93 / 200\n",
      "\n",
      " Epoch 94 / 200\n",
      "\n",
      " Epoch 95 / 200\n",
      "\n",
      " Epoch 96 / 200\n",
      "\n",
      " Epoch 97 / 200\n",
      "\n",
      " Epoch 98 / 200\n",
      "\n",
      " Epoch 99 / 200\n",
      "\n",
      " Epoch 100 / 200\n",
      "\n",
      " Epoch 101 / 200\n",
      "\n",
      " Epoch 102 / 200\n",
      "\n",
      " Epoch 103 / 200\n",
      "\n",
      " Epoch 104 / 200\n",
      "\n",
      " Epoch 105 / 200\n",
      "\n",
      " Epoch 106 / 200\n",
      "\n",
      " Epoch 107 / 200\n",
      "\n",
      " Epoch 108 / 200\n",
      "\n",
      " Epoch 109 / 200\n",
      "\n",
      " Epoch 110 / 200\n",
      "\n",
      " Epoch 111 / 200\n",
      "\n",
      " Epoch 112 / 200\n",
      "\n",
      " Epoch 113 / 200\n",
      "\n",
      " Epoch 114 / 200\n",
      "\n",
      " Epoch 115 / 200\n",
      "\n",
      " Epoch 116 / 200\n",
      "\n",
      " Epoch 117 / 200\n",
      "\n",
      " Epoch 118 / 200\n",
      "\n",
      " Epoch 119 / 200\n",
      "\n",
      " Epoch 120 / 200\n",
      "\n",
      " Epoch 121 / 200\n",
      "\n",
      " Epoch 122 / 200\n",
      "\n",
      " Epoch 123 / 200\n",
      "\n",
      " Epoch 124 / 200\n",
      "\n",
      " Epoch 125 / 200\n",
      "\n",
      " Epoch 126 / 200\n",
      "\n",
      " Epoch 127 / 200\n",
      "\n",
      " Epoch 128 / 200\n",
      "\n",
      " Epoch 129 / 200\n",
      "\n",
      " Epoch 130 / 200\n",
      "\n",
      " Epoch 131 / 200\n",
      "\n",
      " Epoch 132 / 200\n",
      "\n",
      " Epoch 133 / 200\n",
      "\n",
      " Epoch 134 / 200\n",
      "\n",
      " Epoch 135 / 200\n",
      "\n",
      " Epoch 136 / 200\n",
      "\n",
      " Epoch 137 / 200\n",
      "\n",
      " Epoch 138 / 200\n",
      "\n",
      " Epoch 139 / 200\n",
      "\n",
      " Epoch 140 / 200\n",
      "\n",
      " Epoch 141 / 200\n",
      "\n",
      " Epoch 142 / 200\n",
      "\n",
      " Epoch 143 / 200\n",
      "\n",
      " Epoch 144 / 200\n",
      "\n",
      " Epoch 145 / 200\n",
      "\n",
      " Epoch 146 / 200\n",
      "\n",
      " Epoch 147 / 200\n",
      "\n",
      " Epoch 148 / 200\n",
      "\n",
      " Epoch 149 / 200\n",
      "\n",
      " Epoch 150 / 200\n",
      "\n",
      " Epoch 151 / 200\n",
      "\n",
      " Epoch 152 / 200\n",
      "\n",
      " Epoch 153 / 200\n",
      "\n",
      " Epoch 154 / 200\n",
      "\n",
      " Epoch 155 / 200\n",
      "\n",
      " Epoch 156 / 200\n",
      "\n",
      " Epoch 157 / 200\n",
      "\n",
      " Epoch 158 / 200\n",
      "\n",
      " Epoch 159 / 200\n",
      "\n",
      " Epoch 160 / 200\n",
      "\n",
      " Epoch 161 / 200\n",
      "\n",
      " Epoch 162 / 200\n",
      "\n",
      " Epoch 163 / 200\n",
      "\n",
      " Epoch 164 / 200\n",
      "\n",
      " Epoch 165 / 200\n",
      "\n",
      " Epoch 166 / 200\n",
      "\n",
      " Epoch 167 / 200\n",
      "\n",
      " Epoch 168 / 200\n",
      "\n",
      " Epoch 169 / 200\n",
      "\n",
      " Epoch 170 / 200\n",
      "\n",
      " Epoch 171 / 200\n",
      "\n",
      " Epoch 172 / 200\n",
      "\n",
      " Epoch 173 / 200\n",
      "\n",
      " Epoch 174 / 200\n",
      "\n",
      " Epoch 175 / 200\n",
      "\n",
      " Epoch 176 / 200\n",
      "\n",
      " Epoch 177 / 200\n",
      "\n",
      " Epoch 178 / 200\n",
      "\n",
      " Epoch 179 / 200\n",
      "\n",
      " Epoch 180 / 200\n",
      "\n",
      " Epoch 181 / 200\n",
      "\n",
      " Epoch 182 / 200\n",
      "\n",
      " Epoch 183 / 200\n",
      "\n",
      " Epoch 184 / 200\n",
      "\n",
      " Epoch 185 / 200\n",
      "\n",
      " Epoch 186 / 200\n",
      "\n",
      " Epoch 187 / 200\n",
      "\n",
      " Epoch 188 / 200\n",
      "\n",
      " Epoch 189 / 200\n",
      "\n",
      " Epoch 190 / 200\n",
      "\n",
      " Epoch 191 / 200\n",
      "\n",
      " Epoch 192 / 200\n",
      "\n",
      " Epoch 193 / 200\n",
      "\n",
      " Epoch 194 / 200\n",
      "\n",
      " Epoch 195 / 200\n",
      "\n",
      " Epoch 196 / 200\n",
      "\n",
      " Epoch 197 / 200\n",
      "\n",
      " Epoch 198 / 200\n",
      "\n",
      " Epoch 199 / 200\n",
      "\n",
      " Epoch 200 / 200\n",
      "\n",
      "Training Loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    # it can make your experiment reproducible, similar to set  random seed to all options where there needs a random seed.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "print(f'\\nTraining Loss: {train_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f=open(\"C:/Users/sohay/OneDrive/Desktop/BERT/data.json\")\n",
    "data = json.load(f)\n",
    "def get_prediction(str):\n",
    " str = re.sub(r\"[^a-zA-Z ]+\", \"\", str)\n",
    " test_text = [str]\n",
    " model.eval()\n",
    " tokens_test_data = tokenizer(\n",
    " test_text,\n",
    " max_length = max_seq_len,\n",
    " pad_to_max_length=True,\n",
    " truncation=True,\n",
    " return_token_type_ids=False\n",
    " )\n",
    " test_seq = torch.tensor(tokens_test_data[\"input_ids\"])\n",
    " test_mask = torch.tensor(tokens_test_data[\"attention_mask\"])\n",
    " \n",
    " preds = None\n",
    " with torch.no_grad():\n",
    "   preds = model(test_seq.to(device), test_mask.to(device))\n",
    " preds = preds.detach().cpu().numpy()\n",
    " preds = np.argmax(preds, axis = 1)\n",
    " print(\"Intent Identified: \", le.inverse_transform(preds)[0])\n",
    " return le.inverse_transform(preds)[0]\n",
    "def get_response(message): \n",
    "  intent = get_prediction(message)\n",
    "  for i in data['intents']: \n",
    "    if i[\"tag\"] == intent:\n",
    "      result = random.choice(i[\"responses\"])\n",
    "      break\n",
    "  print(f\"Response : {result}\")\n",
    "  return \"Intent: \"+ intent + '\\n' + \"Response: \" + result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent Identified:  name\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'intents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22500\\3814309358.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"why dont you introduce yourself\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22500\\3941923709.py\u001b[0m in \u001b[0;36mget_response\u001b[1;34m(message)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m   \u001b[0mintent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m   \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'intents'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tag\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mintent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"responses\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'intents'"
     ]
    }
   ],
   "source": [
    "get_response(\"why dont you introduce yourself\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bcb7a4420e3136ab632c17d159e5fea5af36ef1d161656b370dc5e9da854d135"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('BERTenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
